name: Pipeline Qualité Eau - CI/CD

on:
  workflow_dispatch: {}
#   push:
#     branches:
#       - main
#       - develop
#   pull_request:
#     branches:
#       - main

env:
  PYTHON_VERSION: '3.10'
  # ⚠️ IMPORTANT : Remplacez cette URL par votre vraie URL Databricks
  # Exemple : https://adb-1234567890123456.12.azuredatabricks.net
  DATABRICKS_HOST: 'https://adb-8445911392469812.12.azuredatabricks.net'  # ⚠️ MODIFIEZ ICI
  CLUSTER_NAME: "Jonathan IMPE's Cluster credential"

jobs:
  # ============================================================
  # JOB 1 : INGESTION LOCALE (GitHub Actions)
  # ============================================================
  ingestion-local:
    name: "📥 Étape 1 - Ingestion Locale"
    runs-on: ubuntu-latest
    
    steps:
      - name: 📦 Checkout du code
        uses: actions/checkout@v4

      - name: 🐍 Configuration Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📚 Installation des dépendances
        run: |
          echo "================================"
          echo "📚 INSTALLATION DES DÉPENDANCES"
          echo "================================"
          
          python -m pip install --upgrade pip
          
          # Installation des dépendances du projet
          if [ -f requirements.txt ]; then
            echo "📄 Installation depuis requirements.txt"
            pip install -r requirements.txt
          fi
          
          # Installation des dépendances Azure (obligatoires)
          echo "☁️  Installation des packages Azure"
          pip install azure-storage-blob azure-identity azure-core
          
          # Installation de papermill pour exécuter les notebooks
          echo "📓 Installation de papermill"
          pip install papermill nbformat nbconvert jupyter
          
          # Installation de python-dotenv si nécessaire
          pip install python-dotenv
          
          echo "✅ Toutes les dépendances sont installées"
          
          # Afficher les packages installés
          echo ""
          echo "📋 Packages Azure installés :"
          pip list | grep azure

      - name: 🔐 Configuration des variables d'environnement
        run: |
          echo "================================"
          echo "🔐 CONFIGURATION DES SECRETS"
          echo "================================"
          
          echo "AZURE_STORAGE_ACCOUNT_NAME=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" >> $GITHUB_ENV
          echo "AZURE_STORAGE_ACCOUNT_KEY=${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}" >> $GITHUB_ENV
          echo "AZURE_STORAGE_CONNECTION_STRING=${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}" >> $GITHUB_ENV
          echo "CONTAINER_RAW=${{ secrets.CONTAINER_RAW }}" >> $GITHUB_ENV
          echo "CONTAINER_BRONZE=${{ secrets.CONTAINER_BRONZE }}" >> $GITHUB_ENV
          
          echo "✅ Variables d'environnement configurées"
          echo "📊 Storage Account: ${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}"
          echo "📊 Container Raw: ${{ secrets.CONTAINER_RAW }}"

      - name: 📝 Vérification du notebook
        run: |
          echo "================================"
          echo "📝 VÉRIFICATION DU NOTEBOOK"
          echo "================================"
          
          if [ ! -f "00_qualite_eau_ingestion.ipynb" ]; then
            echo "❌ Le fichier 00_qualite_eau_ingestion.ipynb n'existe pas"
            exit 1
          fi
          
          echo "✅ Notebook trouvé : 00_qualite_eau_ingestion.ipynb"
          
          # Afficher la structure du notebook
          python3 << EOF
          import json
          with open('00_qualite_eau_ingestion.ipynb', 'r', encoding='utf-8') as f:
              nb = json.load(f)
              print(f"📊 Nombre de cellules : {len(nb['cells'])}")
              print(f"📊 Kernel : {nb['metadata'].get('kernelspec', {}).get('name', 'N/A')}")
          EOF

      - name: 🚀 Exécution du notebook d'ingestion
        run: |
          echo "================================"
          echo "📥 ÉTAPE 1 : INGESTION DES DONNÉES"
          echo "================================"
          
          # Exporter les variables pour le notebook
          export AZURE_STORAGE_ACCOUNT_NAME="${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}"
          export AZURE_STORAGE_ACCOUNT_KEY="${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}"
          export AZURE_STORAGE_CONNECTION_STRING="${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}"
          export CONTAINER_RAW="${{ secrets.CONTAINER_RAW }}"
          export CONTAINER_BRONZE="${{ secrets.CONTAINER_BRONZE }}"
          
          # Exécuter le notebook avec papermill (SANS paramètres)
          papermill \
            00_qualite_eau_ingestion.ipynb \
            00_qualite_eau_ingestion_output.ipynb \
            --log-output \
            --progress-bar \
            --request-save-on-cell-execute
          
          echo ""
          echo "✅ Ingestion terminée avec succès"

      - name: 📊 Vérification des résultats
        if: success()
        run: |
          echo "================================"
          echo "📊 VÉRIFICATION DES RÉSULTATS"
          echo "================================"
          
          echo "✅ Notebook exécuté : 00_qualite_eau_ingestion.ipynb"
          echo "📄 Output généré : 00_qualite_eau_ingestion_output.ipynb"
          
          # Vérifier que le fichier output existe
          if [ -f "00_qualite_eau_ingestion_output.ipynb" ]; then
            echo "✅ Fichier output créé avec succès"
            
            # Afficher un résumé du notebook exécuté
            python3 << EOF
          import json
          with open('00_qualite_eau_ingestion_output.ipynb', 'r', encoding='utf-8') as f:
              nb = json.load(f)
              cells_executed = sum(1 for cell in nb['cells'] if cell.get('execution_count'))
              print(f"📊 Cellules exécutées : {cells_executed}/{len(nb['cells'])}")
          EOF
          else
            echo "⚠️  Fichier output non trouvé"
          fi

      - name: 💾 Upload du notebook exécuté (artifact)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: notebook-ingestion-output
          path: |
            00_qualite_eau_ingestion_output.ipynb
            *.log
          retention-days: 7

      - name: 📋 Affichage des logs en cas d'erreur
        if: failure()
        run: |
          echo "================================"
          echo "📋 LOGS D'ERREUR"
          echo "================================"
          
          if [ -f "00_qualite_eau_ingestion_output.ipynb" ]; then
            echo "📄 Extraction des erreurs du notebook..."
            
            python3 << EOF
          import json
          with open('00_qualite_eau_ingestion_output.ipynb', 'r', encoding='utf-8') as f:
              nb = json.load(f)
              for i, cell in enumerate(nb['cells'], 1):
                  if cell.get('cell_type') == 'code':
                      outputs = cell.get('outputs', [])
                      for output in outputs:
                          if output.get('output_type') == 'error':
                              print(f"\n❌ ERREUR dans la cellule {i}:")
                              print(f"   Type: {output.get('ename', 'N/A')}")
                              print(f"   Message: {output.get('evalue', 'N/A')}")
                              traceback = output.get('traceback', [])
                              if traceback:
                                  print("   Traceback:")
                                  for line in traceback:
                                      print(f"   {line}")
          EOF
          fi

      - name: ❌ Gestion des erreurs
        if: failure()
        run: |
          echo ""
          echo "================================"
          echo "❌ ERREUR LORS DE L'INGESTION"
          echo "================================"
          echo ""
          echo "📄 Consultez les logs ci-dessus pour plus de détails"
          echo "💡 Vérifiez :"
          echo "   - Les credentials Azure sont corrects"
          echo "   - Le container existe"
          echo "   - Les permissions sont configurées"
          echo ""
          exit 1

      - name: ✅ Résumé de l'exécution
        if: success()
        run: |
          echo ""
          echo "================================"
          echo "✅ INGESTION TERMINÉE AVEC SUCCÈS"
          echo "================================"
          echo ""
          echo "📊 Résumé :"
          echo "   ✅ Notebook exécuté : 00_qualite_eau_ingestion.ipynb"
          echo "   ✅ Output disponible : 00_qualite_eau_ingestion_output.ipynb"
          echo "   ✅ Artifacts uploadés : notebook-ingestion-output"
          echo ""
          echo "🎉 Étape 1 du pipeline complétée !"
          echo "================================"

  # ============================================================
  # JOB 2 : TRANSFORMATION RAW TO BRONZE (Databricks)
  # ============================================================
  raw-to-bronze:
    name: "🥉 Étape 2 - Raw to Bronze (Databricks)"
    runs-on: ubuntu-latest
    needs: ingestion-local
    
    steps:
      - name: 📦 Checkout du code
        uses: actions/checkout@v4

      - name: 🐍 Configuration Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: 📚 Installation Databricks CLI
        run: |
          echo "================================"
          echo "📚 INSTALLATION DATABRICKS CLI"
          echo "================================"
          
          pip install databricks-cli requests
          
          echo "✅ Databricks CLI installé"
          databricks --version

      - name: 🔍 Vérification des prérequis
        run: |
          echo "================================"
          echo "🔍 VÉRIFICATION DES PRÉREQUIS"
          echo "================================"
          
          # Vérifier l'URL Databricks
          if [[ "${{ env.DATABRICKS_HOST }}" == *"<workspace-id>"* ]] || [[ "${{ env.DATABRICKS_HOST }}" == *"<region>"* ]]; then
            echo "❌ ERREUR : L'URL Databricks n'est pas configurée !"
            echo "📝 Vous devez modifier la ligne 11 du fichier ci.yml"
            echo "📝 Remplacez : https://adb-<workspace-id>.<region>.azuredatabricks.net"
            echo "📝 Par votre vraie URL Databricks"
            echo ""
            echo "💡 Pour trouver votre URL :"
            echo "   1. Allez sur le portail Azure"
            echo "   2. Ouvrez votre workspace Databricks"
            echo "   3. Copiez l'URL de votre workspace"
            exit 1
          fi
          
          # Vérifier le token
          if [ -z "${{ secrets.TOKEN_AZUREDATABRICKS }}" ]; then
            echo "❌ ERREUR : Le secret TOKEN_AZUREDATABRICKS n'est pas configuré !"
            echo "📝 Ajoutez-le dans : Settings > Secrets and variables > Actions"
            exit 1
          fi
          
          # Vérifier l'email utilisateur
          if [ -z "${{ secrets.DATABRICKS_USER_EMAIL }}" ]; then
            echo "❌ ERREUR : Le secret DATABRICKS_USER_EMAIL n'est pas configuré !"
            echo "📝 Ajoutez-le dans : Settings > Secrets and variables > Actions"
            exit 1
          fi
          
          echo "✅ URL Databricks : ${{ env.DATABRICKS_HOST }}"
          echo "✅ Token configuré : Oui"
          echo "✅ User email configuré : Oui"
          echo "✅ Tous les prérequis sont satisfaits"

      - name: 🔐 Configuration Databricks
        run: |
          echo "================================"
          echo "🔐 CONFIGURATION DATABRICKS"
          echo "================================"
          
          # Créer le répertoire
          mkdir -p ~/.databricks
          
          # Créer le fichier de configuration
          cat > ~/.databrickscfg << 'EOF'
          [DEFAULT]
          host = ${{ env.DATABRICKS_HOST }}
          token = ${{ secrets.TOKEN_AZUREDATABRICKS }}
          EOF
          
          # Remplacer les variables
          sed -i 's|\${{ env.DATABRICKS_HOST }}|${{ env.DATABRICKS_HOST }}|g' ~/.databrickscfg
          sed -i 's|\${{ secrets.TOKEN_AZUREDATABRICKS }}|${{ secrets.TOKEN_AZUREDATABRICKS }}|g' ~/.databrickscfg
          
          echo "✅ Configuration Databricks effectuée"
          echo "🌐 Host: ${{ env.DATABRICKS_HOST }}"
          
          # Vérifier que le fichier est bien créé
          if [ -f ~/.databrickscfg ]; then
            echo "✅ Fichier ~/.databrickscfg créé"
            echo "📄 Contenu (masqué) :"
            sed 's/token = .*/token = ***MASKED***/g' ~/.databrickscfg
          else
            echo "❌ Fichier de configuration non créé"
            exit 1
          fi

      - name: 🧪 Test de connexion Databricks
        run: |
          echo "================================"
          echo "🧪 TEST DE CONNEXION DATABRICKS"
          echo "================================"
          
          echo "🔗 Tentative de connexion à : ${{ env.DATABRICKS_HOST }}"
          
          # Tester la connexion avec plus de détails
          RESPONSE=$(databricks clusters list 2>&1)
          EXIT_CODE=$?
          
          if [ $EXIT_CODE -eq 0 ]; then
            echo "✅ Connexion à Databricks réussie"
            echo ""
            echo "📋 Clusters disponibles :"
            echo "$RESPONSE"
          else
            echo "❌ Échec de connexion à Databricks"
            echo ""
            echo "📋 Message d'erreur :"
            echo "$RESPONSE"
            echo ""
            echo "💡 Causes possibles :"
            echo "   1. Token invalide ou expiré"
            echo "   2. URL Databricks incorrecte"
            echo "   3. Pas de permissions suffisantes"
            echo "   4. Workspace Databricks inaccessible"
            echo ""
            echo "🔧 Solutions :"
            echo "   1. Vérifiez votre token dans Azure Databricks :"
            echo "      - User Settings > Access Tokens"
            echo "   2. Vérifiez l'URL du workspace"
            echo "   3. Vérifiez les permissions du token"
            exit 1
          fi

      - name: 🔍 Recherche du cluster
        id: get-cluster
        run: |
          echo "================================"
          echo "🔍 RECHERCHE DU CLUSTER"
          echo "================================"
          
          echo "🔍 Recherche du cluster : '${{ env.CLUSTER_NAME }}'"
          
          # Lister tous les clusters
          CLUSTERS_JSON=$(databricks clusters list --output JSON 2>&1)
          
          echo "📋 Clusters trouvés :"
          echo "$CLUSTERS_JSON" | python3 -c "
          import sys, json
          try:
              data = json.load(sys.stdin)
              clusters = data.get('clusters', [])
              if not clusters:
                  print('   ⚠️  Aucun cluster trouvé')
              else:
                  for c in clusters:
                      print(f\"   - {c['cluster_name']} (ID: {c['cluster_id']}, État: {c['state']})\")
          except Exception as e:
              print(f'   ❌ Erreur lors du parsing : {e}')
          " || echo "   ❌ Erreur lors de la lecture des clusters"
          
          # Récupérer l'ID du cluster
          CLUSTER_ID=$(echo "$CLUSTERS_JSON" | python3 -c "
          import sys, json
          try:
              data = json.load(sys.stdin)
              clusters = data.get('clusters', [])
              target = '''${{ env.CLUSTER_NAME }}'''
              for c in clusters:
                  if c.get('cluster_name') == target:
                      print(c['cluster_id'])
                      sys.exit(0)
              print('NOT_FOUND')
          except Exception as e:
              print('ERROR')
          " 2>/dev/null)
          
          echo ""
          echo "🔎 Résultat de la recherche : $CLUSTER_ID"
          
          if [ "$CLUSTER_ID" == "NOT_FOUND" ] || [ "$CLUSTER_ID" == "ERROR" ] || [ -z "$CLUSTER_ID" ]; then
            echo ""
            echo "❌ Cluster non trouvé : '${{ env.CLUSTER_NAME }}'"
            echo ""
            echo "💡 Vérifiez :"
            echo "   1. Le nom exact du cluster dans Databricks"
            echo "   2. Les majuscules/minuscules (sensible à la casse)"
            echo "   3. Les espaces et caractères spéciaux"
            echo ""
            echo "📝 Nom recherché : '${{ env.CLUSTER_NAME }}'"
            exit 1
          fi
          
          echo "✅ Cluster trouvé !"
          echo "🆔 ID : $CLUSTER_ID"
          echo "CLUSTER_ID=$CLUSTER_ID" >> $GITHUB_OUTPUT
          echo "CLUSTER_ID=$CLUSTER_ID" >> $GITHUB_ENV

      - name: 🔄 Vérification et démarrage du cluster
        run: |
          echo "================================"
          echo "🔄 GESTION DU CLUSTER"
          echo "================================"
          
          echo "🔍 Vérification de l'état du cluster ${{ steps.get-cluster.outputs.CLUSTER_ID }}..."
          
          # Récupérer l'état du cluster
          CLUSTER_INFO=$(databricks clusters get --cluster-id ${{ steps.get-cluster.outputs.CLUSTER_ID }} 2>&1)
          STATE=$(echo "$CLUSTER_INFO" | python3 -c "import sys, json; print(json.load(sys.stdin).get('state', 'UNKNOWN'))" 2>/dev/null || echo "UNKNOWN")
          
          echo "📊 État actuel du cluster : $STATE"
          
          if [ "$STATE" == "TERMINATED" ] || [ "$STATE" == "TERMINATING" ]; then
            echo "🚀 Démarrage du cluster en cours..."
            databricks clusters start --cluster-id ${{ steps.get-cluster.outputs.CLUSTER_ID }}
            
            echo "⏳ Attente du démarrage du cluster..."
            TIMEOUT=600  # 10 minutes
            ELAPSED=0
            
            while [ $ELAPSED -lt $TIMEOUT ]; do
              sleep 15
              ELAPSED=$((ELAPSED + 15))
              
              STATE=$(databricks clusters get --cluster-id ${{ steps.get-cluster.outputs.CLUSTER_ID }} 2>/dev/null | \
                python3 -c "import sys, json; print(json.load(sys.stdin).get('state', 'UNKNOWN'))" 2>/dev/null || echo "UNKNOWN")
              
              echo "⏱️  [$ELAPSED s] État : $STATE"
              
              if [ "$STATE" == "RUNNING" ]; then
                echo "✅ Cluster démarré et prêt"
                break
              elif [ "$STATE" == "ERROR" ]; then
                echo "❌ Erreur lors du démarrage du cluster"
                exit 1
              fi
            done
            
            if [ $ELAPSED -ge $TIMEOUT ]; then
              echo "❌ Timeout : le cluster n'a pas démarré dans les temps"
              exit 1
            fi
            
          elif [ "$STATE" == "RUNNING" ]; then
            echo "✅ Cluster déjà en cours d'exécution"
          elif [ "$STATE" == "PENDING" ] || [ "$STATE" == "RESTARTING" ]; then
            echo "⏳ Cluster en cours de démarrage, attente..."
            sleep 30
            
            STATE=$(databricks clusters get --cluster-id ${{ steps.get-cluster.outputs.CLUSTER_ID }} 2>/dev/null | \
              python3 -c "import sys, json; print(json.load(sys.stdin).get('state', 'UNKNOWN'))" 2>/dev/null)
            
            if [ "$STATE" == "RUNNING" ]; then
              echo "✅ Cluster prêt"
            else
              echo "⚠️  Cluster toujours en démarrage (état: $STATE)"
            fi
          else
            echo "⚠️  État du cluster inconnu ou problématique : $STATE"
          fi

      - name: 📤 Upload du notebook vers Databricks
        run: |
          echo "================================"
          echo "📤 UPLOAD DU NOTEBOOK"
          echo "================================"
          
          NOTEBOOK_PATH="/Workspace/Users/${{ secrets.DATABRICKS_USER_EMAIL }}/pipeline/raw_to_bronze_result_and_plv"
          
          echo "📄 Notebook local : raw_to_bronze_result_and_plv.ipynb"
          echo "📍 Destination : $NOTEBOOK_PATH"
          
          # Vérifier que le notebook existe
          if [ ! -f "raw_to_bronze_result_and_plv.ipynb" ]; then
            echo "❌ Le fichier raw_to_bronze_result_and_plv.ipynb n'existe pas"
            ls -la *.ipynb
            exit 1
          fi
          
          echo "✅ Fichier trouvé localement"
          
          # Upload du notebook
          UPLOAD_RESULT=$(databricks workspace import \
            raw_to_bronze_result_and_plv.ipynb \
            "$NOTEBOOK_PATH" \
            --language PYTHON \
            --format JUPYTER \
            --overwrite 2>&1)
          
          UPLOAD_EXIT=$?
          
          if [ $UPLOAD_EXIT -eq 0 ]; then
            echo "✅ Notebook uploadé avec succès"
          else
            echo "❌ Échec de l'upload du notebook"
            echo "📋 Message d'erreur :"
            echo "$UPLOAD_RESULT"
            exit 1
          fi

      - name: 🚀 Exécution du notebook sur Databricks
        id: run-notebook
        run: |
          echo "================================"
          echo "🚀 EXÉCUTION DU NOTEBOOK"
          echo "================================"
          
          NOTEBOOK_PATH="/Workspace/Users/${{ secrets.DATABRICKS_USER_EMAIL }}/pipeline/raw_to_bronze_result_and_plv"
          
          echo "📓 Notebook : $NOTEBOOK_PATH"
          echo "🖥️  Cluster : ${{ steps.get-cluster.outputs.CLUSTER_ID }}"
          
          # Créer et lancer le job
          RUN_OUTPUT=$(databricks runs submit --json "{
            \"run_name\": \"Pipeline CI/CD - Raw to Bronze\",
            \"existing_cluster_id\": \"${{ steps.get-cluster.outputs.CLUSTER_ID }}\",
            \"notebook_task\": {
              \"notebook_path\": \"$NOTEBOOK_PATH\",
              \"base_parameters\": {}
            },
            \"timeout_seconds\": 3600
          }" 2>&1)
          
          RUN_EXIT=$?
          
          echo "📋 Réponse de l'API (code: $RUN_EXIT) :"
          echo "$RUN_OUTPUT"
          
          if [ $RUN_EXIT -ne 0 ]; then
            echo "❌ Échec de la soumission du job"
            exit 1
          fi
          
          # Extraire le run_id
          RUN_ID=$(echo "$RUN_OUTPUT" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('run_id', ''))" 2>/dev/null)
          
          if [ -z "$RUN_ID" ]; then
            echo "❌ Impossible de récupérer le run_id"
            exit 1
          fi
          
          echo "✅ Job lancé avec succès"
          echo "🆔 Run ID : $RUN_ID"
          echo "RUN_ID=$RUN_ID" >> $GITHUB_OUTPUT
          echo "RUN_ID=$RUN_ID" >> $GITHUB_ENV
          
          # Afficher le lien vers le job
          echo "🔗 Lien : ${{ env.DATABRICKS_HOST }}/#job/runs/$RUN_ID"

      - name: ⏳ Attente de la fin du job
        run: |
          echo "================================"
          echo "⏳ SUIVI DE L'EXÉCUTION"
          echo "================================"
          
          RUN_ID="${{ steps.run-notebook.outputs.RUN_ID }}"
          echo "🆔 Suivi du run : $RUN_ID"
          echo ""
          
          TIMEOUT=1800  # 30 minutes
          ELAPSED=0
          
          while [ $ELAPSED -lt $TIMEOUT ]; do
            sleep 20
            ELAPSED=$((ELAPSED + 20))
            
            # Récupérer l'état du job
            JOB_INFO=$(databricks runs get --run-id $RUN_ID 2>/dev/null)
            
            LIFE_CYCLE_STATE=$(echo "$JOB_INFO" | python3 -c "import sys, json; print(json.load(sys.stdin)['state']['life_cycle_state'])" 2>/dev/null || echo "UNKNOWN")
            
            echo "⏱️  [$ELAPSED s] État : $LIFE_CYCLE_STATE"
            
            if [ "$LIFE_CYCLE_STATE" == "TERMINATED" ]; then
              RESULT_STATE=$(echo "$JOB_INFO" | python3 -c "import sys, json; print(json.load(sys.stdin)['state']['result_state'])" 2>/dev/null)
              
              echo ""
              echo "🏁 Job terminé"
              echo "📊 Résultat : $RESULT_STATE"
              
              if [ "$RESULT_STATE" == "SUCCESS" ]; then
                echo "✅ Job exécuté avec succès"
                exit 0
              else
                echo "❌ Job échoué : $RESULT_STATE"
                
                # Afficher le message d'erreur
                STATE_MESSAGE=$(echo "$JOB_INFO" | python3 -c "import sys, json; print(json.load(sys.stdin)['state'].get('state_message', 'Aucun message'))" 2>/dev/null)
                echo "📄 Message : $STATE_MESSAGE"
                
                exit 1
              fi
            elif [ "$LIFE_CYCLE_STATE" == "SKIPPED" ] || [ "$LIFE_CYCLE_STATE" == "INTERNAL_ERROR" ]; then
              echo "❌ Erreur : $LIFE_CYCLE_STATE"
              exit 1
            fi
          done
          
          if [ $ELAPSED -ge $TIMEOUT ]; then
            echo "❌ Timeout : le job n'a pas terminé dans les temps"
            exit 1
          fi

      - name: 📋 Récupération des logs
        if: always()
        run: |
          echo "================================"
          echo "📋 LOGS DU JOB"
          echo "================================"
          
          RUN_ID="${{ steps.run-notebook.outputs.RUN_ID }}"
          
          if [ ! -z "$RUN_ID" ]; then
            echo "🆔 Run ID : $RUN_ID"
            databricks runs get-output --run-id $RUN_ID 2>&1 || echo "⚠️  Impossible de récupérer les logs"
          else
            echo "⚠️  Aucun run_id disponible"
          fi

      - name: ✅ Résumé de l'étape 2
        if: success()
        run: |
          echo ""
          echo "================================"
          echo "✅ RAW TO BRONZE TERMINÉ"
          echo "================================"
          echo ""
          echo "📊 Résumé :"
          echo "   ✅ Notebook exécuté : raw_to_bronze_result_and_plv.ipynb"
          echo "   ✅ Cluster : ${{ env.CLUSTER_NAME }}"
          echo "   ✅ Run ID : ${{ steps.run-notebook.outputs.RUN_ID }}"
          echo ""
          echo "🎉 Étape 2 du pipeline complétée !"
          echo "================================"

      - name: ❌ Gestion des erreurs
        if: failure()
        run: |
          echo ""
          echo "================================"
          echo "❌ ERREUR ÉTAPE 2 : RAW TO BRONZE"
          echo "================================"
          echo ""
          echo "💡 Vérifiez :"
          echo "   - L'URL Databricks (ligne 11 du ci.yml)"
          echo "   - Le token Databricks (TOKEN_AZUREDATABRICKS)"
          echo "   - L'email utilisateur (DATABRICKS_USER_EMAIL)"
          echo "   - Le nom du cluster est exact"
          echo "   - Le cluster est accessible"
          echo "   - Le notebook existe et est valide"
          echo "   - Les logs ci-dessus pour plus de détails"
          echo ""
          exit 1